{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2431f2c",
   "metadata": {},
   "source": [
    "# This notebook runs Sequential Monte Carlo on 4 parameters $x,y,z,q$ with uniform prior to fit $\\Gamma$-OU and CIR models on real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a8ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load before numpy to restrict its usage of cores, otherwise it will use all cores when doing @\n",
    "import os\n",
    "os.environ[\"BLAS_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cb3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as ti\n",
    "import loompy as lp\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Scientific computing imports\n",
    "import numpy as np\n",
    "from numpy.fft import irfftn\n",
    "from numpy.random import choice\n",
    "from scipy.stats import rv_discrete, poisson, nbinom, gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy \n",
    "from scipy import integrate\n",
    "\n",
    "# PyMC3-related imports\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13defae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd9f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1186b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mffang/workspace/CIR/GVFP_2021/smc_results\n"
     ]
    }
   ],
   "source": [
    "%cd smc_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50faebf4",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ebc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function that converts between (x, y) qualitative regime coordinates to original parameters.\n",
    "def convert_xy_to_params(x, y, beta, gamma, K_avg):\n",
    "    kappa = (beta + gamma)*(x/(1-x))\n",
    "    a_over_th = 1/y - 1\n",
    "    theta = np.sqrt(kappa*K_avg/a_over_th)\n",
    "    a = K_avg*kappa/theta\n",
    "    return a, kappa, theta\n",
    "\n",
    "\n",
    "# Sample from flattened 2D probability distribution p. \n",
    "# mx = [mx0, mx1] is the shape of the 2D domain we're sampling.\n",
    "def sample_from_p(mx, num_data_points, p_flat):\n",
    "    x_N, x_M = np.arange(mx[0]), np.arange(mx[1])\n",
    "    X_N, X_M = np.meshgrid(x_N, x_M, indexing='ij')    # get grid of possible values\n",
    "    x_choices = np.arange(np.prod(mx))                 # represent each grid point as a point in a 1D vector\n",
    "    \n",
    "    samples = choice(x_choices, size=num_data_points, replace=True, p=p_flat)\n",
    "    d_N, d_M = X_N.flatten()[samples], X_M.flatten()[samples]    \n",
    "    return d_N, d_M\n",
    "\n",
    "\n",
    "# Get maximum of a 2D array\n",
    "def get_2D_max(array):\n",
    "    return np.unravel_index(array.argmax(), array.shape)\n",
    "\n",
    "\n",
    "# Get KDE for smooth-looking heatmaps.\n",
    "def get_2D_KDE(x_stats, y_stats, x_min=0, x_max=1, y_min=0, y_max=1):\n",
    "    num_pts = 100                          # hyperparameter\n",
    "    x_arg = np.linspace(x_min, x_max, num_pts)\n",
    "    y_arg = np.linspace(y_min, y_max, num_pts)\n",
    "\n",
    "    X_arg, Y_arg = np.meshgrid(x_arg, y_arg, indexing='ij')      # grid of points      X0, X1\n",
    "\n",
    " \n",
    "    positions = np.vstack([X_arg.ravel(), Y_arg.ravel()])\n",
    "    kernel = gaussian_kde([x_stats, y_stats])\n",
    "    KDE = np.reshape(kernel(positions).T, X_arg.shape)\n",
    "    return KDE, x_arg, y_arg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baffcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constitutive model likelihood function.\n",
    "def get_Poiss_2sp(mx, params):\n",
    "    beta, gamma, a, kappa, theta = params \n",
    "    K_avg = (a*theta)/kappa\n",
    "    mu_N, mu_M = K_avg/beta, K_avg/gamma\n",
    "    \n",
    "    x_N, x_M = np.arange(mx[0]), np.arange(mx[1])\n",
    "    X_N, X_M = np.meshgrid(x_N, x_M, indexing='ij')\n",
    "    \n",
    "    return poisson.pmf(X_N, mu_N)*poisson.pmf(X_M, mu_M)\n",
    "\n",
    "\n",
    "# Mixture model likelihood function.\n",
    "def get_NB_2sp(mx, params):\n",
    "    beta, gamma, a, kappa, theta = params \n",
    "    \n",
    "    # Get generating function argument\n",
    "    u = []\n",
    "    half = mx[:]\n",
    "    half[-1] = mx[-1]//2 + 1\n",
    "    for i in range(len(mx)):\n",
    "        l = np.arange(half[i])\n",
    "        u_ = np.exp(-2j*np.pi*l/mx[i])-1\n",
    "        u.append(u_)\n",
    "    g = np.meshgrid(*[u_ for u_ in u], indexing='ij')\n",
    "    for i in range(len(mx)):\n",
    "        g[i] = g[i].flatten()\n",
    "    \n",
    "    # Get generating function\n",
    "    gf = np.exp(- (a/kappa)*np.log(1 - theta*(g[0]/beta + g[1]/gamma)))\n",
    "    gf = gf.reshape(tuple(half))\n",
    "                              \n",
    "    Pss = irfftn(gf, s=mx)                        # Get Pss by inverse fast Fourier transform\n",
    "    Pss = np.abs(Pss)/np.sum(np.abs(Pss))           # Normalize\n",
    "    return Pss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f771b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gauss,w_gauss = scipy.special.roots_legendre(60, mu=False)\n",
    "\n",
    "def get_gf_GOU_2sp_ODE(g0, g1, params):\n",
    "    beta_0, beta_1, a, kappa, theta = params     # get parameters\n",
    "    \n",
    "    c0 = (g0) + (beta_0/(beta_1 - beta_0))*(g1)       #  relevant linear combinations of g_i\n",
    "    c1 = - (beta_0/(beta_1 - beta_0))*(g1)   \n",
    "    \n",
    "    min_fudge, max_fudge = 1, 10                                     # Determine integration time scale / length\n",
    "    dt = np.min([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*min_fudge\n",
    "    t_max = np.max([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*max_fudge\n",
    "    num_tsteps = int(np.ceil(t_max/dt))\n",
    "    \n",
    "#     t_array = np.linspace(0, t_max, num_tsteps+1)\n",
    "#     t_array = t_array.reshape((1, num_tsteps + 1))\n",
    "    t_array = (t_max*(x_gauss+1)/2)[None,:]\n",
    "    \n",
    "    q = np.zeros((g0.shape[0], num_tsteps + 1), dtype=np.complex64)    # initialize array to store ODE\n",
    "    c0 = c0.reshape((c0.shape[0],1))\n",
    "    c1 = c1.reshape((c1.shape[0],1))\n",
    "\n",
    "    q0 = np.array(theta*c0*(np.exp(-beta_0*t_array) - np.exp(-kappa*t_array))/(kappa - beta_0), dtype=np.complex64)\n",
    "    q1 = np.array(theta*c1*(np.exp(-beta_1*t_array) - np.exp(-kappa*t_array))/(kappa - beta_1), dtype=np.complex64)\n",
    "    q = q0 + q1\n",
    "    \n",
    "    integrand = np.array(q/(1-q), dtype=np.complex64)\n",
    "    \n",
    "#     print(integrand.shape)\n",
    "#     print(w_gauss.shape)\n",
    "    integral=np.matmul(integrand,w_gauss[:,None]).sum(1)/2*t_max\n",
    "#     integral = np.trapz(integrand, dx=dt, axis=1)     # integrate ODE solution\n",
    "    gf = np.exp( a*integral)               # get generating function\n",
    "    return gf\n",
    "\n",
    "\n",
    "# Get Pss for 2 species GOU model via ODE method\n",
    "def get_GOU_2sp(mx, params):\n",
    "    # Get generating function argument\n",
    "    u = []\n",
    "    half = np.copy(mx[:])\n",
    "    half[-1] = mx[-1]//2 + 1\n",
    "    for i in range(len(mx)):\n",
    "        l = np.arange(half[i])\n",
    "        u_ = np.exp(-2j*np.pi*l/mx[i])-1\n",
    "        u.append(u_)\n",
    "    g = np.meshgrid(*[u_ for u_ in u], indexing='ij')\n",
    "    for i in range(len(mx)):\n",
    "        g[i] = g[i].flatten()\n",
    "    \n",
    "    # Get generating function\n",
    "    gf = get_gf_GOU_2sp_ODE(g[0], g[1], params)                    \n",
    "    gf = gf.reshape(tuple(half))\n",
    "    \n",
    "    Pss = irfftn(gf, s=mx)                        # Get Pss by inverse fast Fourier transform\n",
    "    Pss = np.abs(Pss)/np.sum(np.abs(Pss))           # Normalize\n",
    "    return Pss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e707d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines the above functions into one to reduce overhead associated with Python function calls.\n",
    "# Helpful when doing expensive posterior sampling (since many likelihood function calls are required).\n",
    "def ll_GOU(phi, mx, data):\n",
    "    # Get parameters\n",
    "    x, y, z, q = phi\n",
    "    beta = 1/z-1\n",
    "    gamma = 1/q-1\n",
    "    K_avg = 1\n",
    "    \n",
    "    kappa = (beta + gamma)*(x/(1-x))\n",
    "    a_over_th = 1/y - 1\n",
    "    theta = np.sqrt(kappa*K_avg/a_over_th)\n",
    "    a = K_avg*kappa/theta\n",
    "    \n",
    "    params = [beta, gamma, a, kappa, theta]\n",
    "    \n",
    "    \n",
    "    # Get generating function argument\n",
    "    u = []\n",
    "    half = mx[:]\n",
    "    half[-1] = mx[-1]//2 + 1\n",
    "    for i in range(len(mx)):\n",
    "        l = np.arange(half[i])\n",
    "        u_ = np.exp(-2j*np.pi*l/mx[i])-1\n",
    "        u.append(u_)\n",
    "    g = np.meshgrid(*[u_ for u_ in u], indexing='ij')\n",
    "    for i in range(len(mx)):\n",
    "        g[i] = g[i].flatten()\n",
    "    \n",
    "    # Get generating function\n",
    "    beta_0 = beta\n",
    "    beta_1 = gamma\n",
    "    \n",
    "    c0 = (g[0]) + (beta_0/(beta_1 - beta_0))*(g[1])       #  relevant linear combinations of g_i\n",
    "    c1 = - (beta_0/(beta_1 - beta_0))*(g[1])   \n",
    "    \n",
    "    min_fudge, max_fudge = 0.5, 10                                     # Determine integration time scale / length\n",
    "    dt = np.min([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*min_fudge\n",
    "    t_max = np.max([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*max_fudge\n",
    "    num_tsteps = int(np.ceil(t_max/dt))\n",
    "    \n",
    "    t_array = np.linspace(0, t_max, num_tsteps+1)\n",
    "    t_array = t_array.reshape((1, num_tsteps + 1))\n",
    "    \n",
    "    q = np.zeros((c0.shape[0], num_tsteps + 1), dtype=np.complex64)    # initialize array to store ODE\n",
    "    c0 = c0.reshape((c0.shape[0],1))\n",
    "    c1 = c1.reshape((c1.shape[0],1))\n",
    "    q0 = theta*c0*(np.exp(-beta_0*t_array) - np.exp(-kappa*t_array))/(kappa - beta_0) \n",
    "    q1 = theta*c1*(np.exp(-beta_1*t_array) - np.exp(-kappa*t_array))/(kappa - beta_1)\n",
    "    q = q0 + q1\n",
    "\n",
    "    integrand = q/(1-q)\n",
    "    integral = np.trapz(integrand, dx=dt, axis=1)     # integrate ODE solution\n",
    "    gf = np.exp( a*integral)               # get generating function\n",
    "    \n",
    "    gf = gf.reshape(tuple(half))\n",
    "    \n",
    "    Pss = irfftn(gf, s=mx)                        # Get Pss by inverse fast Fourier transform\n",
    "    Pss = np.abs(Pss)/np.sum(np.abs(Pss))           # Normalize\n",
    "\n",
    "    lp = np.log(Pss)\n",
    "    result = np.sum(lp[data])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74af471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODE for 2 species CIR model\n",
    "def f_2sp(q, t, c0, c1, params):\n",
    "    beta_0, beta_1, a, kappa, theta = params\n",
    "    result = - kappa*q + theta*q*q + kappa*( c0*np.exp(-beta_0*t) + c1*np.exp(-beta_1*t)  ) \n",
    "    return result\n",
    "\n",
    "\n",
    "# Vectorized RK4 implementation for 2 species CIR model\n",
    "def RK4_2sp(q, f, t, c0, c1, step_size, param):\n",
    "    j1 = f(q, t, c0, c1, param)\n",
    "    j2 = f(q + (step_size/2)*j1, t + (step_size/2), c0, c1, param)   \n",
    "    j3 = f(q + (step_size/2)*j2, t + (step_size/2), c0, c1, param)   \n",
    "    j4 = f(q + (step_size)*j3, t + (step_size), c0, c1, param)  \n",
    "    \n",
    "    q_new = q + (step_size/6)*(j1 + 2*j2 + 2*j3 + j4)\n",
    "    return q_new\n",
    "\n",
    "\n",
    "# Get 2 species CIR generating function using ODE method\n",
    "def get_gf_CIR_2sp(g0, g1, params):\n",
    "    beta_0, beta_1, a, kappa, theta = params     # get parameters\n",
    "    \n",
    "    c0 = (g0) + (beta_0/(beta_1 - beta_0))*(g1)       #  relevant linear combinations of g_i\n",
    "    c1 = - (beta_0/(beta_1 - beta_0))*(g1)   \n",
    "    \n",
    "    min_fudge, max_fudge = 0.5, 10                                     # Determine integration time scale / length\n",
    "    dt = np.min([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*min_fudge\n",
    "    t_max = np.max([1/kappa, 1/theta, 1/beta_0, 1/beta_1])*max_fudge\n",
    "    num_tsteps = int(np.ceil(t_max/dt))\n",
    "     \n",
    "    q = np.zeros((g0.shape[0], num_tsteps + 1), dtype=np.complex64)    # initialize array to store ODE\n",
    "    \n",
    "    # Solve ODE using RK4 method \n",
    "    for i in range(0, num_tsteps):\n",
    "        t = i*dt\n",
    "        q[:,i+1] = RK4_2sp(q[:,i], f_2sp, t, c0, c1, dt, params)\n",
    "        \n",
    "    integral = np.trapz(q, dx=dt, axis=1)     # integrate ODE solution\n",
    "    gf = np.exp((a*theta/kappa)*integral)               # get generating function\n",
    "    return gf\n",
    "\n",
    "\n",
    "# Get Pss for 2 species CIR model via ODE method\n",
    "def get_CIR_2sp(mx, params):\n",
    "    # Get generating function argument\n",
    "    u = []\n",
    "    half = mx[:]\n",
    "    half[-1] = mx[-1]//2 + 1\n",
    "    for i in range(len(mx)):\n",
    "        l = np.arange(half[i])\n",
    "        u_ = np.exp(-2j*np.pi*l/mx[i])-1\n",
    "        u.append(u_)\n",
    "    g = np.meshgrid(*[u_ for u_ in u], indexing='ij')\n",
    "    for i in range(len(mx)):\n",
    "        g[i] = g[i].flatten()\n",
    "    \n",
    "    # Get generating function\n",
    "    gf = get_gf_CIR_2sp(g[0], g[1], params)                    \n",
    "    gf = gf.reshape(tuple(half))\n",
    "                              \n",
    "    Pss = irfftn(gf, s=mx)                        # Get Pss by inverse fast Fourier transform\n",
    "    Pss = np.abs(Pss)/np.sum(np.abs(Pss))           # Normalize\n",
    "    return Pss\n",
    "\n",
    "\n",
    "# Log likelihood of CIR model given data. Uses (x,y) as input instead of (kappa, theta).\n",
    "def ll_CIR(phi, mx, data):\n",
    "    # Get parameters\n",
    "    x, y, z, q = phi\n",
    "    beta = 1/z-1\n",
    "    gamma = 1/q-1\n",
    "    K_avg = 1\n",
    "    \n",
    "    kappa = (beta + gamma)*(x/(1-x))\n",
    "    a_over_th = 1/y - 1\n",
    "    theta = np.sqrt(kappa*K_avg/a_over_th)\n",
    "    a = K_avg*kappa/theta\n",
    "    \n",
    "    params = [beta, gamma, a, kappa, theta]\n",
    "    \n",
    "    Pss = get_CIR_2sp(mx, params)    # Compute Pss\n",
    "\n",
    "    lp = np.log(Pss)\n",
    "    result = np.sum(lp[data])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6fc1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is necessary for interfacing with PymC3.\n",
    "\n",
    "class LogLike(tt.Op):\n",
    "    \n",
    "    itypes = [tt.dvector] # expects a vector of parameter values when called\n",
    "    otypes = [tt.dscalar] # outputs a single scalar value (the log likelihood)\n",
    "    \n",
    "    def __init__(self, mx, data, likelihood):\n",
    "        \n",
    "        # add inputs as class attributes\n",
    "        self.mx = mx\n",
    "        self.data = data\n",
    "        self.likelihood = likelihood\n",
    "        \n",
    "    def perform(self, node, inputs, outputs):\n",
    "        \n",
    "        phi, = inputs # this contains parmeters\n",
    "        logl = self.likelihood(phi, self.mx, self.data) # calls the log-likelihood function\n",
    "        outputs[0][0] = np.array(logl) # output the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd9a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets parameter posteriors via smc.\n",
    "def get_parameter_posteriors_smc(string_ID, mx, data, ll_func, draws_=1000, chains_=2, cores_=2):\n",
    "    \"\"\"\"Arguments changed for sample_smc function. Here is pymc3 3.8\"\"\"\n",
    "    # Parameter bounds\n",
    "    epsilon = 0.005\n",
    "    x_min, x_max = epsilon, 1-epsilon\n",
    "    y_min, y_max = epsilon, 1-epsilon\n",
    "    \n",
    "    # Define log likelihood\n",
    "    logl_op = LogLike(mx, data, ll_func)\n",
    "    def logl_fun(phi):\n",
    "        return logl_op(phi)\n",
    "    \n",
    "    # Define PyMC3 model\n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "        # Priors\n",
    "        x_ = pm.Uniform('x', lower=x_min, upper=x_max)\n",
    "        y_ = pm.Uniform('y', lower=y_min, upper=y_max)\n",
    "        z_ = pm.Uniform('z', lower=x_min, upper=x_max)\n",
    "        q_ = pm.Uniform('q', lower=y_min, upper=y_max)\n",
    "\n",
    "        phi = tt.as_tensor_variable([x_, y_, z_, q_])\n",
    "\n",
    "        # Likelihood\n",
    "        pm.Potential('likelihood', logl_fun(phi))\n",
    "        \n",
    "        \n",
    "    # Run PyMC3 model\n",
    "    #start_time = ti.time()\n",
    "    with model:\n",
    "        trace = pm.sample_smc(draws = draws_, chains = chains_, cores = cores_)\n",
    "    #print(\"--- %s seconds ---\" % (ti.time() - start_time))\n",
    "        \n",
    "    # Plot and save trace\n",
    "    #with model:\n",
    "    #    axes = az.plot_trace(trace)\n",
    "    #    fig = axes.ravel()[0].figure\n",
    "    #    #fig.savefig(\"smc_results/trace_\"+string_ID+\".png\", bbox_inches='tight')\n",
    "    #    fig.savefig(\"trace_\"+string_ID+\".pdf\", bbox_inches='tight')\n",
    "        \n",
    "    return trace\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2b8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smc_wrapper(Input):\n",
    "    data, gene_ID, model = Input\n",
    "    d_N, d_M = data\n",
    "    mx = [np.max(d_N)+10,np.max(d_M)+10]\n",
    "    \n",
    "    if model == \"CIR\":\n",
    "        ID = gene_ID+\"_CIR\"\n",
    "        trace = get_parameter_posteriors_smc(gene_ID+\"_CIR\", mx, data, ll_func=ll_CIR, chains_=1, cores_=1)\n",
    "    else:\n",
    "        ID = gene_ID+\"_GOU\"\n",
    "        trace = get_parameter_posteriors_smc(gene_ID+\"_GOU\", mx, data, ll_func=ll_GOU, chains_=1, cores_=1)\n",
    "\n",
    "    with open(ID+'_trace.pickle', 'wb') as f:\n",
    "        pickle.dump(trace, f)\n",
    "\n",
    "    return trace.report.log_marginal_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07318fe",
   "metadata": {},
   "source": [
    "## SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b74a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mffang/workspace/CIR/GVFP_2021/smc_results\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7001552",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['allen_C01_glu','allen_B08_glu','allen_H12_glu','allen_F08_glu']\n",
    "genes = [ 'Aftph', 'Mark1', 'Psma2', 'Ppp1r2', 'Nucks1', 'Ktn1', \n",
    "         'Gabra4', 'Aplp2', 'Srpk1','Pou6f1', 'Tmem65', 'Bace1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79cc22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2022 Oct 25\n",
    "samples = ['allen_C01_Glutamatergic','allen_B08_Glutamatergic','allen_H12_Glutamatergic','allen_F08_Glutamatergic']\n",
    "genes = [ 'Birc6', 'Ube2k','Pum1','Nf1','Rbm25','Hprt','Cap1','Ywhaq','Pnisr','Ywhah','Pura','Ccdc39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22264497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "Inputs =[]\n",
    "for sample in samples:\n",
    "    with lp.connect('../loom/'+sample+'.loom') as ds:\n",
    "        S = ds.layers['spliced'][:]\n",
    "        U = ds.layers['unspliced'][:]\n",
    "        gene_names = ds.ra['gene_name']\n",
    "\n",
    "    for gene in genes:\n",
    "        data_ID = sample+\"_\"+gene \n",
    "        i = np.where(gene_names==gene)[0]\n",
    "        d_M = S[i].astype(int)\n",
    "        d_N = U[i].astype(int)\n",
    "        data = [d_N, d_M]\n",
    "        if not exists(data_ID+\"_CIR_trace.pickle\"):\n",
    "            Inputs.append((data, data_ID, \"CIR\"))\n",
    "        if not exists(data_ID+\"_GOU_trace.pickle\"):\n",
    "            Inputs.append((data, data_ID, \"GOU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808c2561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([array([[4, 1, 2, ..., 0, 1, 4]]),\n",
       "   array([[ 64,  29,  37, ...,  37,  92, 104]])],\n",
       "  'allen_B08_Glutamatergic_Ywhah',\n",
       "  'GOU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be80e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(min(len(Inputs),2)) as p:\n",
    "    lmls = p.map(smc_wrapper, Inputs, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ef610bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "n_samples,n_genes = len(samples),len(genes)\n",
    "BF = np.empty((n_samples,n_genes))\n",
    "BF[:] = np.nan\n",
    "for j,sample in enumerate(samples):\n",
    "    for i,gene in enumerate(genes):    \n",
    "        with open(sample+\"_\"+gene+'_GOU_trace.pickle', 'rb') as f:\n",
    "            trace_GOU = pickle.load(f)\n",
    "        with open(sample+\"_\"+gene+'_CIR_trace.pickle', 'rb') as f:\n",
    "            trace_CIR = pickle.load(f)\n",
    "        BF[j,i]= (trace_CIR.report.log_marginal_likelihood - trace_GOU.report.log_marginal_likelihood)/np.log(10)\n",
    "np.save('bfs_20221027.npy',BF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
